{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# なぜ、メジャーリーグ貧乏球団から線形回帰を学ぶか？\n",
    "\n",
    "* TensorFlow の練習になるから\n",
    "* 基礎は重要だから\n",
    "  * 最尤原理から線形回帰を捉え直すと、ロジスティック回帰とディープラーニングに自然につながる。\n",
    "\n",
    "\n",
    "* オークランドアスレチックスの話が面白いから\n",
    "  * [\"Moneyball:The Power of Sport Analytics\" edX MITx:15071x The Analytics Edge](https://courses.edx.org/courses/course-v1:MITx+15.071x_3+1T2016/courseware/f8d71d64418146f18a066d7f0379678c/6324edb8a22c4e35b937490647bfe203/?activate_block_id=block-v1%3AMITx%2B15.071x_3%2B1T2016%2Btype%40sequential%2Bblock%406324edb8a22c4e35b937490647bfe203)\n",
    "    * 2000年代初頭、貧乏球団オークランドアスレチックスは統計的推論を駆使することで、プレーオフ常連となった。\n",
    "       * 当時、「野球はスポーツではなく金銭ゲーム」と言われ、良い選手はことごとく金満球団へ引き抜かれていた。\n",
    "       * そんななか、オークランドアステチックスが選手に支払っている総年棒は、金満球団レッドソックスの1/3だった。にもかかわらず、勝率はほぼ同じ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from math import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形回帰\n",
    "\n",
    "2002年にオークランドアスレチックスのビリー・ビーンが行った解析を、線形回帰で再現してみる。\n",
    "\n",
    "* すなわち、2002年よりも前のデータを使って、統計的モデルを作ってみる。\n",
    "\n",
    "\n",
    "## メジャーリーグの試合データ\n",
    "\n",
    "[Baseball-Reference.com](http://www.baseball-reference.com/)が提供しているデータを、edXのサイトからダウンロード。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG  \n",
       "0           NaN  162  0.317  0.415  \n",
       "1           5.0  162  0.306  0.378  \n",
       "2           4.0  162  0.315  0.403  \n",
       "3           NaN  162  0.331  0.428  \n",
       "4           NaN  162  0.335  0.424  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball = pd.read_csv(\"https://d37djvu3ytnwxt.cloudfront.net/assets/courseware/v1/dfb1bb5463c388fb167745888e3a6dd9/asset-v1:MITx+15.071x_3+1T2016+type@asset+block/baseball.csv\")\n",
    "baseball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2002年よりも前のデータを取り出しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "moneyball = baseball[ baseball.Year < 2002 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得点のモデル\n",
    "$$y = b + {\\bf x \\cdot w}$$\n",
    "\n",
    "* 従属変数\n",
    "  * $y$ : シーズン中の総得点\n",
    "* 独立変数 \n",
    "  * ベクトル ${\\bf x} = ( x_1  \\, x_2 )$ \n",
    "     * $x_1$ : On-Base Percentage (OBP) , $x_2$ : Slugging Percentage (SLG)\n",
    "* モデルパラメーター\n",
    "  * b : バイアス項\n",
    "  * ベクトル ${\\bf w}^T = (w_1 \\, w_2) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データとモデルを対応させるために\n",
    "\n",
    "#### 行列、ベクトルによる表現\n",
    "\n",
    "データセットのなかの複数のレコードをまとめて表現するために、従属変数をベクトル、独立変数を行列であらわすとプログラミングしやすくなる。\n",
    "\n",
    "$$ {\\bf y} = b + X {\\bf w} $$\n",
    "\n",
    "$$ {\\bf y^{data}} = {\\bf y} + {\\bf \\epsilon} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 独立変数  \n",
    "  * $X$ 行列 : i番目の行$(x_{i1} \\, x_{i2})$が、i番目のレコードのなかのOLG, SLGに対応する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder( tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 従属変数\n",
    "  * $\\bf y^{data}$ ベクトル : i番目の成分が、i番目のレコードのなかの得点に対応する。\n",
    "  * $\\bf y$ ベクトル : モデルによって計算された得点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yData = tf.placeholder( tf.float32, [ None, 1])\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "w = tf.Variable(tf.zeros([2,1]))\n",
    "y = tf.add( b,  tf.matmul( x, w) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 確率モデルとしての得点モデル\n",
    "\n",
    "* データのなかの得点$\\bf y^{data}$には、モデルでは表しきれない誤差（ばらつき、ゆらぎ、擾乱）$\\bf \\epsilon$ が含まれていると考える。\n",
    "\n",
    "* 独立変数$x_1, x_2$に対して、どれだけの誤差$\\epsilon$が出てくるかを決めることはできず、何らかの確率分布にしたがって$\\epsilon$が分布していると考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルパラメーターの推定法 -- 最尤法\n",
    "\n",
    "最尤原理\n",
    "* 「現実のデータは、確率モデルのなかで最大のものが実現された結果である」と仮定する。\n",
    "\n",
    "最尤法\n",
    "* データが得られる確率を尤度（もっともらしさ）$L$と呼び、その関数の引数がモデルパラメータであると考える。\n",
    "* すると、尤度関数$L({\\bf w})$を最大にするようなモデルパラメーター$\\bf w$の値が現実で実現されている、ということになる。\n",
    "* すなわち、$ \\partial L / \\partial {\\bf w} = 0$ を解くことで、モデルパラメーター$\\bf w$の値を決定できる。\n",
    "* $L$は非常に小さくなるので、数値計算で解くときには、$L$の代わりに対数尤度$ log{L(\\bf w)}$ を用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差$\\epsilon$が正規分布に従うと仮定すると、対数尤度は次のようになる。\n",
    "\n",
    "$$log{L(\\bf w)} \\propto  | {\\bf y - y^{data}} |^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差関数\n",
    "\n",
    "機械学習の分野では、モデルパラメーターを決めるために最小化する関数を、「誤差関数 (error function)」と呼ぶ。\n",
    "\n",
    "* 上記の得点のように、モデルを線形関数としてあらわすと、最尤法での誤差関数と、最小二乗法での誤差関数が一致する。\n",
    "$$ E =  | {\\bf y - y^{data}} |^2 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errFunc = tf.reduce_sum( tf.square( y - yData )  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* しかし、ロジスティック回帰（のような他の機械学習）やディープラーニングは一致しない。\n",
    "\n",
    "* そして、ロジスティック回帰やディープラーニングでは、最小二乗法ではなく、最尤法を用いてモデルパラメーターを決めている。\n",
    "\n",
    "なので、ディープラーニングを含む機械学習分野では、最尤法などの統計的推論の基礎を理解しておくことで、見通しが良くなるのだと思う。\n",
    "\n",
    "#### 計算機科学分野の用語は独特\n",
    "\n",
    "ちなみに、誤差関数の代わりに損失関数(loss function)、目的関数(objective function)といった用語が使われることもある。\n",
    "\n",
    "* また、特殊関数の誤差関数 $erf(x}$　と機械学習の誤差関数は、まったく別のものである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差関数を最小化する方法\n",
    "\n",
    "#### 勾配降下法\n",
    "\n",
    "$${\\bf w}^{new} \\leftarrow {\\bf w}^{old} - \\eta \\left( \\frac{\\partial E}{\\partial {\\bf w}} \\right)_{\\bf w^{old}}  $$ \n",
    "\n",
    "* $\\partial E / \\partial {\\bf w}$を求めるときに、学習データのなかのレコードをひとつづつ使うアルゴリズムを「確率的勾配降下法」と呼ぶ。\n",
    "* 学習データを複数のバッチに分割して、$\\partial E / \\partial {\\bf w}$を求めるときに、ひとつづつバッチを使っていくアルゴリズムを「ミニバッチによる勾配降下法」と呼ぶ。\n",
    "\n",
    "ここでは、ミニバッチによる勾配降下法で粗く最適化してから、勾配降下法で細かく最適化してみる。最適化アルゴリズムは、学習率$\\eta$を自動調整するAdmaOptimizerを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainStep = tf.train.AdamOptimizer().minimize( errFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "class CyclicMinibatch :\n",
    "    def __init__( self, data) :\n",
    "        self.counter = 0\n",
    "        self.data = data\n",
    "    \n",
    "    def nextBatch( self, sz) :\n",
    "        if  self.counter + sz < len(self.data) :\n",
    "            prevCounter = self.counter\n",
    "            self.counter += sz\n",
    "            return self.data[ prevCounter: self.counter]\n",
    "        else :\n",
    "            prevCounter = self.counter\n",
    "            self.counter = 0\n",
    "            return self.data[ prevCounter : len(self.data)]\n",
    "\n",
    "testMinibatch = CyclicMinibatch( range(33))\n",
    "print testMinibatch.nextBatch(5)\n",
    "print testMinibatch.nextBatch(15)\n",
    "print testMinibatch.nextBatch(20)\n",
    "print testMinibatch.nextBatch(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run( tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習のためのデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902, 1) (10, 1)\n",
      "(902, 2) (10, 2)\n",
      "703.809312639\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "trainX = np.array( zip( moneyball.OBP, moneyball.SLG))\n",
    "numTrain, dummy =  trainX.shape\n",
    "\n",
    "trainY = np.array( moneyball.RS)\n",
    "trainY = trainY.reshape( [trainY.size, 1])\n",
    "\n",
    "cyclicTrainY = CyclicMinibatch( trainY)\n",
    "cyclicTrainX = CyclicMinibatch( trainX)\n",
    "\n",
    "print trainY.shape, cyclicTrainY.nextBatch(10).shape\n",
    "print trainX.shape, cyclicTrainX.nextBatch(10).shape\n",
    "\n",
    "print trainY.mean()\n",
    "print b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチによる勾配降下法で粗く最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 5000, RMSE : 93.239365\n",
      "Step : 10000, RMSE : 93.218053\n",
      "Step : 15000, RMSE : 93.198448\n",
      "Step : 20000, RMSE : 93.180412\n",
      "Step : 25000, RMSE : 93.162787\n",
      "Step : 30000, RMSE : 93.145590\n",
      "Step : 35000, RMSE : 93.128845\n",
      "Step : 40000, RMSE : 93.112225\n",
      "Step : 45000, RMSE : 93.095968\n",
      "Step : 50000, RMSE : 93.080056\n",
      "Step : 55000, RMSE : 93.064119\n",
      "Step : 60000, RMSE : 93.048097\n",
      "Step : 65000, RMSE : 93.032241\n",
      "Step : 70000, RMSE : 93.016512\n",
      "Step : 75000, RMSE : 93.000939\n",
      "Step : 80000, RMSE : 92.985464\n",
      "Step : 85000, RMSE : 92.970103\n",
      "Step : 90000, RMSE : 92.954868\n",
      "Step : 95000, RMSE : 92.939711\n",
      "Step : 100000, RMSE : 92.924638\n"
     ]
    }
   ],
   "source": [
    "iterNum = 1000 * 100;\n",
    "monitorInterval = iterNum / 20\n",
    "batchSz = numTrain / 10\n",
    "\n",
    "biasSet = tf.assign(b, tf.constant( [ trainY.mean()]))\n",
    "sess.run( biasSet)\n",
    "\n",
    "for i in range(1, iterNum+1) :\n",
    "    batchX = cyclicTrainX.nextBatch( batchSz)\n",
    "    batchY = cyclicTrainY.nextBatch( batchSz)\n",
    "    sess.run( trainStep, feed_dict={ x:batchX, yData:batchY})\n",
    "    if i % monitorInterval == 0:\n",
    "        errFuncVal = sess.run( errFunc, feed_dict={ x:trainX, yData:trainY})\n",
    "        rmse = sqrt( errFuncVal / numTrain  )\n",
    "        print 'Step : %d, RMSE : %f' % ( i, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配降下法で最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 200000, RMSE : 84.037484\n",
      "Step : 400000, RMSE : 75.230149\n",
      "Step : 600000, RMSE : 66.660061\n",
      "Step : 800000, RMSE : 58.414624\n",
      "Step : 1000000, RMSE : 50.449839\n",
      "Step : 1200000, RMSE : 42.922224\n",
      "Step : 1400000, RMSE : 36.106260\n",
      "Step : 1600000, RMSE : 30.483099\n",
      "Step : 1800000, RMSE : 26.813997\n",
      "Step : 2000000, RMSE : 25.714320\n",
      "Step : 2200000, RMSE : 25.289685\n",
      "Step : 2400000, RMSE : 24.984604\n",
      "Step : 2600000, RMSE : 24.803507\n",
      "Step : 2800000, RMSE : 24.748757\n",
      "Step : 3000000, RMSE : 24.748757\n"
     ]
    }
   ],
   "source": [
    "rmseStart = rmse\n",
    "prevRmse = rmse * 10.0\n",
    "monitorInterval = 200000\n",
    "i = 0\n",
    "\n",
    "while( abs(prevRmse - rmse) > rmse * 1.0e-8 ) :\n",
    "    i += 1\n",
    "    sess.run( trainStep, feed_dict={ x:trainX, yData:trainY})\n",
    "    if i % monitorInterval == 0:\n",
    "        errFuncVal = sess.run( errFunc, feed_dict={ x:trainX, yData:trainY})\n",
    "        prevRmse = rmse\n",
    "        rmse = sqrt( errFuncVal / numTrain  )\n",
    "        print 'Step : %d, RMSE : %f' % ( i, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル式のテスト\n",
    "\n",
    "#### 今回、線形回帰で求めた式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model formula : y = -804.627075 + 2737.767822 x1 + 1584.908569 x2\n"
     ]
    }
   ],
   "source": [
    "estY = sess.run(b)\n",
    "estW = sess.run(w)\n",
    "print \"Model formula : y = %f + %f x1 + %f x2\" % (estY[0] , estW[0], estW[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [edX MITx:15071x The Analytics Edge](https://courses.edx.org/courses/course-v1:MITx+15.071x_3+1T2016/courseware/f8d71d64418146f18a066d7f0379678c/6324edb8a22c4e35b937490647bfe203/?activate_block_id=block-v1%3AMITx%2B15.071x_3%2B1T2016%2Btype%40sequential%2Bblock%406324edb8a22c4e35b937490647bfe203)の演習で、Rを使って求めた式\n",
    "\n",
    "$$ y =  -804.63 + 2737.77 x_1 + 1584.91 x_2 $$\n",
    "\n",
    "\n",
    "両者は、ほぼ一致している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（正式のデータ分析であれば、テスト用のデータを2002年の試合データから取り出して、モデル式の精度をテストするところだが、今回はこれでよしとする。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "\n",
    "TensorFlow の基本を学び、正しく動作するpythonスクリプトを書くことができた。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
